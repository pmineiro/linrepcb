{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2cf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EasyAcc:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.sum = 0\n",
    "        self.sumsq = 0\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        self.n += 1\n",
    "        self.sum += other\n",
    "        self.sumsq += other*other\n",
    "        return self\n",
    "\n",
    "    def __isub__(self, other):\n",
    "        self.n += 1\n",
    "        self.sum -= other\n",
    "        self.sumsq += other*other\n",
    "        return self\n",
    "\n",
    "    def mean(self):\n",
    "        return self.sum / max(self.n, 1)\n",
    "\n",
    "    def var(self):\n",
    "        from math import sqrt\n",
    "        return sqrt(self.sumsq / max(self.n, 1) - self.mean()**2)\n",
    "\n",
    "    def semean(self):\n",
    "        from math import sqrt\n",
    "        return self.var() / sqrt(max(self.n, 1))\n",
    "    \n",
    "# {'uid': '0000031909', \n",
    "#  'title': 'Girls Ballet Tutu Neon Pink\\n', \n",
    "#  'content': 'High quality 3 layer ballet tutu. 12 inches in length', \n",
    "#  'target_ind': [0, 1, 192406, 1327309, 1371116, 1371888, 1461720, 1476259, 1509175, 1509181, 1509182, 1535940, 1578041, 1578155, 1604047, 1604766, 1615188, 1969579, 2030361, 2186983, 2186984, 2191027, 2227069, 2342392, 2514733, 2515122, 2515192, 2515198, 2515203, 2516838, 2516839, 2775528], \n",
    "#  'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
    "\n",
    "def categoryCount():\n",
    "    from collections import defaultdict\n",
    "    import gzip\n",
    "    import json\n",
    "    import zipfile\n",
    "        \n",
    "    counts = defaultdict(int)\n",
    "    examples = 0\n",
    "    \n",
    "    with zipfile.ZipFile('Amazon-3M.raw.zip') as fzip:\n",
    "        with fzip.open('Amazon-3M.raw/trn.json.gz') as fbin:\n",
    "            with gzip.open(fbin) as f:\n",
    "                for line in f:\n",
    "                    obj = json.loads(line)\n",
    "                    examples += 1\n",
    "                    \n",
    "                    for label in obj['target_ind']:\n",
    "                        counts[label] += 1\n",
    "\n",
    "    indices = { v: n for n, v in enumerate(counts) }\n",
    "            \n",
    "    return counts, examples, indices\n",
    "\n",
    "def embedData():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import gzip\n",
    "    import json\n",
    "    import zipfile\n",
    "    \n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    batchsize = 20\n",
    "    \n",
    "    with zipfile.ZipFile('Amazon-3M.raw.zip') as fzip:\n",
    "        with fzip.open('Amazon-3M.raw/trn.json.gz') as fbin:\n",
    "            with gzip.open(fbin) as f:\n",
    "                batchencode, batchlabels = [], []\n",
    "\n",
    "                for line in f:\n",
    "                    obj = json.loads(line)\n",
    "                    batchencode.append(obj['title'])\n",
    "                    batchencode.append(obj['content'])\n",
    "                    batchlabels.append(obj['target_ind'])\n",
    "                \n",
    "                    if len(batchencode) >= batchsize:\n",
    "                        embed = model.encode(batchencode)\n",
    "                    \n",
    "                        for n, labels in enumerate(batchlabels):\n",
    "                            embtitle, embcontent = embed[2*n], embed[2*n+1]\n",
    "                            yield { 'title': embtitle, \n",
    "                                    'content': embcontent, \n",
    "                                    'labels': labels }\n",
    "                            batchencode, batchlabels = [], []\n",
    "                                         \n",
    "    if len(batchencode):\n",
    "        embed = model.encode(batchencode)\n",
    "                    \n",
    "        for n, labels in enumerate(batchlabels):\n",
    "            embtitle, embcontent = embed[2*n], embed[2*n+1]\n",
    "            yield { 'title': embtitle, \n",
    "                    'content': embcontent, \n",
    "                    'labels': labels }\n",
    "            batchencode, batchlabels = [], []\n",
    "            \n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        from tqdm.notebook import tqdm\n",
    "        \n",
    "        _, examples, self.indices = categoryCount()\n",
    "        \n",
    "        Xs = []\n",
    "        ys = []\n",
    "        for n, what in tqdm(enumerate(embedData()), total=examples):\n",
    "            title = torch.tensor(what['title'])\n",
    "            content = torch.tensor(what['content'])\n",
    "            Xs.append(torch.cat((title, content)).unsqueeze(0))\n",
    "            thisy = set(self.indices[label] for label in what['labels'])\n",
    "            ys.append(thisy)\n",
    "\n",
    "        self.Xs = torch.cat(Xs, dim=0)\n",
    "        self.ys = ys\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.Xs.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ys = torch.zeros(len(self.indices)).float()\n",
    "        for l in self.ys[index]:\n",
    "            ys[l] = 1.0\n",
    "        return self.Xs[index], ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dc2b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_constant_answer': 1889237,\n",
       " 'best_constant_average_bceloss': 0.0001429955723006122,\n",
       " 'best_constant_average_accuracy': 0.00699342627244093}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best constant predictor\n",
    "# if you don't beat this, you have a problem\n",
    "\n",
    "def bestconstant():\n",
    "    from math import fsum\n",
    "    \n",
    "    counts, examples, _ = categoryCount()\n",
    "    log_loss = torch.nn.BCELoss()\n",
    "    sumloss = EasyAcc()\n",
    "    \n",
    "    positive = torch.Tensor([1])\n",
    "    negative = torch.Tensor([0])\n",
    "    \n",
    "    for m, k in enumerate(counts.keys()):\n",
    "        n = counts[k]\n",
    "        predict = torch.Tensor([ n / examples ])\n",
    "        sumloss += n * log_loss(predict, positive).item()\n",
    "        sumloss += (examples - n) * log_loss(predict, negative).item()\n",
    "        \n",
    "    denom = examples * len(counts.keys())\n",
    "            \n",
    "    return { 'best_constant_answer': max((v, k) for k, v in counts.items())[1], \n",
    "             'best_constant_average_bceloss': sumloss.sum / denom,\n",
    "             'best_constant_average_accuracy': max(v for v in counts.values()) / examples }            \n",
    "\n",
    "bestconstant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77462939",
   "metadata": {},
   "source": [
    "# This takes time run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec63e1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e59a95886204497b340619a68b8058e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def makeMyDataset():\n",
    "    import gzip\n",
    "    \n",
    "    foo = MyDataset()\n",
    "    with gzip.open(f'amazon3m.pickle.gz', 'wb') as handle:\n",
    "        import pickle\n",
    "        pickle.dump(foo, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "makeMyDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285f6e3",
   "metadata": {},
   "source": [
    "# Load Cached Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c23449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMyDataset():\n",
    "    import gzip\n",
    "    \n",
    "    with gzip.open(f'amazon3m.pickle.gz', 'rb') as handle:\n",
    "        import pickle\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e2423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, device):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.zeros(d, d, device=device))\n",
    "        self.afunc = torch.nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X + 0.001 * self.afunc(torch.matmul(X, self.W))\n",
    "\n",
    "class BilinearResidual(torch.nn.Module):\n",
    "    def __init__(self, dobs, daction, device, depth):\n",
    "        super(BilinearResidual, self).__init__()\n",
    "        \n",
    "        self.block = torch.nn.Sequential(*[ResidualBlock(dobs, device) for _ in range(depth) ])\n",
    "        self.W = torch.nn.Parameter(torch.zeros(dobs, daction-1, device=device))\n",
    "        self.b = torch.nn.Parameter(torch.zeros(1, device=device))\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, Xs, Zs):\n",
    "        return torch.matmul(torch.matmul(self.block(Xs), self.W), Zs[:,:-1].T) + Zs[:,-1] + self.b\n",
    "        \n",
    "    def preq1(self, logits):\n",
    "        return self.sigmoid(logits)\n",
    "\n",
    "class RankOneDetset(object):\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.N, self.K, self.D = actions.shape\n",
    "        self.device = actions.device\n",
    "        \n",
    "        self.batcheye = torch.eye(self.D, device=self.device).unsqueeze(0).expand(self.N, -1, -1)\n",
    "        self.S = self.batcheye.clone()\n",
    "        self.Sinv = self.batcheye.clone()\n",
    "        self.logdetfac = torch.zeros(self.N, device=self.device)\n",
    "        \n",
    "    def computePhi(self, i): \n",
    "        # Sprime_a <- replace column i of S with action a where det(S)=1\n",
    "        # Sprime_a = S + (a - S_i) e_i^\\top = S + u v^\\top\n",
    "        # det(Sprime_a) = det(S) (1 + e_i^\\top S^{-1} (a - S_i))\n",
    "        #               = (1 - (S^{-T} e_i)^\\top S_i) + (S^{-T} e_i)^\\top a\n",
    "        #               = 0 + \\phi^\\top a\n",
    "        \n",
    "        #Sinvtopei = torch.linalg.solve(torch.transpose(self.S, 1, 2), self.batcheye[:,:,i])\n",
    "        Sinvtopei = self.Sinv[:, i, :]\n",
    "        return Sinvtopei, self.logdetfac\n",
    "    \n",
    "    def updateCoord(self, i, fstar, astar):\n",
    "        Y = torch.gather(input=self.actions, \n",
    "                         dim=1, \n",
    "                         index=astar.reshape(self.N, 1, 1).expand(self.N, 1, self.D)\n",
    "                        ).squeeze(1)\n",
    "        Y /= torch.exp(self.logdetfac).reshape(self.N, 1)\n",
    "\n",
    "        # replace column i of S with y\n",
    "        # -----------------------------\n",
    "        # Sprime = S + (y - S_i) e_i^\\top = S + u v^\\top\n",
    "        # Sprime^{-1} = S^{-1} - 1/(1 + v^\\top S^{-1} u) (S^{-1} u) (v^\\top S^{-1})^\\top\n",
    "        \n",
    "        u = Y - self.S[:, :, i]\n",
    "        Sinvu = torch.bmm(self.Sinv, u.unsqueeze(2)).squeeze(2)\n",
    "        vtopSinv = self.Sinv[:, i, :]\n",
    "        vtopSinvu = Sinvu[:, i].unsqueeze(1).unsqueeze(2)\n",
    "        self.Sinv -= (1 / (1 + vtopSinvu)) * torch.bmm(Sinvu.unsqueeze(2), vtopSinv.unsqueeze(1))\n",
    "        \n",
    "        self.S[:,:,i] = Y\n",
    "        thislogdet = 1/self.D * (torch.log(fstar) - self.logdetfac)\n",
    "        scale = torch.exp(thislogdet).reshape(self.N, 1, 1)\n",
    "        self.S /= scale\n",
    "        self.Sinv *= scale\n",
    "        self.logdetfac += thislogdet\n",
    "    \n",
    "class SpannerEG(torch.nn.Module):\n",
    "    def __init__(self, actions, epsilon, tzero):\n",
    "        super(SpannerEG, self).__init__()\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.tzero = tzero\n",
    "        self.t = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batchactions = actions.unsqueeze(0)\n",
    "            self.spanner = self._make_spanner(batchactions)\n",
    "            self.samplingprobs = torch.ones(*self.spanner.shape, device=self.spanner.device)\n",
    "            \n",
    "    def _make_spanner(self, actions):\n",
    "        from math import log\n",
    "\n",
    "        # Algorithm 4 Approximate Barycentric Identification (Awerbuch and Kleinberg, 2008)\n",
    "        C = 2\n",
    "        \n",
    "        N, K, D = actions.shape\n",
    "        device = actions.device\n",
    "        #detset = NaiveDetset(actions)\n",
    "        detset = RankOneDetset(actions)\n",
    "        design = torch.zeros(N, D, device=device).long()\n",
    "                \n",
    "        for i in range(D):\n",
    "            psi, _ = detset.computePhi(i)\n",
    "            dets = torch.abs(torch.bmm(actions, psi.unsqueeze(2))).squeeze(2) \n",
    "            fstar, astar = torch.max(dets, dim=1)\n",
    "            design[:, i] = astar\n",
    "            detset.updateCoord(i, fstar, astar)\n",
    "                        \n",
    "        for _ in range(int(D * log(D))):\n",
    "            replaced = False\n",
    "            for i in range(D):\n",
    "                psi, logdetfac = detset.computePhi(i)\n",
    "                dets = torch.abs(torch.bmm(actions, psi.unsqueeze(2))).squeeze(2)\n",
    "                fstar, astar = torch.max(dets, dim=1)\n",
    "                                \n",
    "                if torch.any(fstar >= C * torch.exp(logdetfac)):\n",
    "                    design[:, i] = astar\n",
    "                    detset.updateCoord(i, fstar, astar)\n",
    "                    replaced = True\n",
    "                    break\n",
    "                    \n",
    "            if not replaced:\n",
    "                break\n",
    "                \n",
    "        return design\n",
    "\n",
    "    def sample(self, fhat, *, k, r):\n",
    "        epsilon = self.epsilon * pow(self.tzero / (self.t + self.tzero), 1/3)\n",
    "        self.t += 1\n",
    "        \n",
    "        exploit = torch.topk(fhat, k=k, dim=1, sorted=True)\n",
    "        exploreindex = torch.multinomial(input=self.samplingprobs.expand(fhat.shape[0], -1),\n",
    "                                         num_samples=r,\n",
    "                                         replacement=False)\n",
    "        explore = torch.gather(input=self.spanner[0,:].expand(fhat.shape[0], -1), dim=1, index=exploreindex)\n",
    "        shouldexplore = (torch.rand(size=(fhat.shape[0], r), device=fhat.device) < epsilon).long()\n",
    "        sample = exploit.indices\n",
    "        sample[:,(k-r):] += shouldexplore * (explore - exploit.indices[:,(k-r):])\n",
    "        return sample\n",
    "\n",
    "class Embedding(object):\n",
    "    def __init__(self, seed, naction):\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.cooc = defaultdict(lambda: defaultdict(int))\n",
    "        self.counts = defaultdict(int)\n",
    "        self.examples = 0\n",
    "        self.naction = naction\n",
    "    \n",
    "    def consume(self, ys):        \n",
    "        self.examples += ys.shape[0]\n",
    "        for row in range(ys.shape[0]):\n",
    "            nonzeros = [ v.item() for v in torch.nonzero(ys[row]) ]\n",
    "            for a in nonzeros:\n",
    "                assert 0 <= a < self.naction, a\n",
    "                self.counts[a] += 1\n",
    "                for b in nonzeros:\n",
    "                    assert 0 <= b < self.naction, b\n",
    "                    self.cooc[a][b] += 1\n",
    "            \n",
    "    def fit(self, rank):\n",
    "        from math import log, log1p, sqrt\n",
    "        \n",
    "        remap = {}\n",
    "        \n",
    "        # Hellinger PCA\n",
    "        row_indices, col_indices, values = [], [], []\n",
    "        for a, na in self.counts.items():\n",
    "            if a not in remap:\n",
    "                remap[a] = len(remap)\n",
    "                \n",
    "            for b, cooc_ab in self.cooc[a].items():\n",
    "                if b not in remap:\n",
    "                    remap[b] = len(remap)\n",
    "                \n",
    "                row_indices.append(remap[a])\n",
    "                col_indices.append(remap[b])\n",
    "                values.append(sqrt(cooc_ab / na))\n",
    "                \n",
    "        # throws \"not implemented error\" ... #sadlife\n",
    "        #\n",
    "        # coo = torch.sparse_coo_tensor([ row_indices, col_indices ], values)\n",
    "        # csr = coo.to_sparse_csr()\n",
    "        # return torch.svd_lowrank(csr, q=d+6, niter=2, M=None), indices\n",
    "\n",
    "        from sklearn.decomposition import TruncatedSVD\n",
    "        from scipy.sparse import coo_matrix\n",
    "\n",
    "        coo = coo_matrix( ( values, ( row_indices, col_indices ) ), \n",
    "                          shape = (len(remap), len(remap)) )\n",
    "        csr = coo.tocsr()\n",
    "\n",
    "        svd = TruncatedSVD(n_components=rank, \n",
    "                           algorithm='randomized',\n",
    "                           n_iter=2,\n",
    "                           random_state=self.seed)\n",
    "        svd.fit(csr)\n",
    "        Z = sqrt(self.examples) * torch.tensor(svd.transform(csr))\n",
    "        \n",
    "        assert self.examples > 0\n",
    "        defaultphat = 1 / self.examples\n",
    "        bias = torch.ones(Z.shape[0]) * (log(defaultphat) - log1p(-defaultphat))\n",
    "        for a, na in self.counts.items():\n",
    "            assert 0 <= a < self.naction\n",
    "            assert 0 < na < self.examples, (a, na, self.examples)\n",
    "            phat = na / self.examples\n",
    "            bias[remap[a]] = log(phat) - log1p(-phat)\n",
    "            \n",
    "        Z = torch.cat((Z, bias.unsqueeze(1)), dim=1)\n",
    "        inverseremap = { v: k for k, v in remap.items() }\n",
    "        remapTensor = torch.LongTensor([ inverseremap[n] for n in range(len(remap)) ]).unsqueeze(0)\n",
    "        \n",
    "        return Z, remapTensor\n",
    "    \n",
    "def embed(dataset, batch_size, pretrain, rank, seed):\n",
    "    from tqdm.notebook import tqdm\n",
    "    from math import sqrt\n",
    "    import time\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    splitseed = seed+1\n",
    "        \n",
    "    predata, _ = torch.utils.data.random_split(dataset,\n",
    "                                               lengths=[ pretrain, len(dataset) - pretrain ],\n",
    "                                               generator=torch.Generator().manual_seed(splitseed))\n",
    "    generator = torch.utils.data.DataLoader(predata, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    embedding = Embedding(seed=seed+2, naction=len(dataset.indices))\n",
    "    \n",
    "    print('embed', flush=True)\n",
    "    for bno, (Xs, ys) in tqdm(enumerate(generator), total=(pretrain//batch_size)):\n",
    "        embedding.consume(ys)\n",
    "        \n",
    "    print('fit', flush=True)\n",
    "    Z, remap = embedding.fit(rank)\n",
    "    print('done', flush=True)\n",
    "    \n",
    "    return Z.float(), remap, splitseed\n",
    "    \n",
    "def presup(dataset, actions, initlr, tzero, batch_size, depth, pretrain, cuda, seed):\n",
    "    from math import sqrt\n",
    "    import time\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    Zs, remap, splitseed = actions\n",
    "    \n",
    "    if cuda:\n",
    "        Zs = Zs.cuda()\n",
    "        remap = remap.cuda()\n",
    "        \n",
    "    predata, _ = torch.utils.data.random_split(dataset,\n",
    "                                               lengths=[ pretrain, len(dataset) - pretrain ],\n",
    "                                               generator=torch.Generator().manual_seed(splitseed))\n",
    "    generator = torch.utils.data.DataLoader(predata, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    \n",
    "    print('{:<5s}\\t{:<8s}\\t{:<8s}\\t{:<8s}\\t{:<8s}\\t{:<8s}'.format('n', 'loss', 'since last', 'acc', 'acc since last', 'dt (sec)'), flush=True)\n",
    "    avloss, acc, sincelast, accsincelast = EasyAcc(), EasyAcc(), EasyAcc(), EasyAcc()\n",
    "\n",
    "    model = None\n",
    "    log_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for bno, (Xs, preys) in enumerate(generator):\n",
    "        if bno > 1:\n",
    "            break\n",
    "            \n",
    "        Xs, preys = Xs.to(Zs.device), preys.to(Zs.device)\n",
    "\n",
    "        if model is None:\n",
    "            model = BilinearResidual(dobs=Xs.shape[1], daction=Zs.shape[1], device=Zs.device, depth=depth)\n",
    "            opt = torch.optim.Adam(( p for p in model.parameters() if p.requires_grad ), lr=initlr)\n",
    "            scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda = lambda t: sqrt(tzero) / sqrt(tzero + t))\n",
    "            start = time.time()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            ys = torch.gather(input=preys, dim=1, index=remap.expand(preys.shape[0], -1))        \n",
    "\n",
    "        opt.zero_grad()\n",
    "        score = model.forward(0.0001 * Xs, Zs)\n",
    "        loss = log_loss(score, ys)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(score, dim=1)\n",
    "            ypred = torch.gather(input=ys, dim=1, index=pred.unsqueeze(1))\n",
    "            acc += torch.mean(ypred).float()\n",
    "            accsincelast += torch.mean(ypred).float()\n",
    "            avloss += loss\n",
    "            sincelast += loss\n",
    "\n",
    "        if bno & (bno - 1) == 0:\n",
    "            print('{:<5d}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}'.format(avloss.n, avloss.mean(), sincelast.mean(), \n",
    "                                                                                    acc.mean(), accsincelast.mean(), time.time() - start), \n",
    "                  flush=True)\n",
    "            sincelast, accsincelast = EasyAcc(), EasyAcc()\n",
    "\n",
    "    print('{:<5d}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}\\t{:<8.5g}'.format(avloss.n, avloss.mean(), sincelast.mean(), \n",
    "                                                                            acc.mean(), accsincelast.mean(), time.time() - start), \n",
    "          flush=True)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def train(dataset, *, k, r, model, actions, initlr, tzero, epsilon, epsilontzero, batch_size, pretrain, cuda, seed):\n",
    "    from math import sqrt\n",
    "    import time\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    Zs, remap, splitseed = actions\n",
    "    \n",
    "    if cuda:\n",
    "        Zs = Zs.cuda()\n",
    "        remap = remap.cuda()\n",
    "    \n",
    "    _, traindata = torch.utils.data.random_split(dataset,\n",
    "                                                 lengths=[ pretrain, len(dataset) - pretrain ],\n",
    "                                                 generator=torch.Generator().manual_seed(splitseed))\n",
    "    generator = torch.utils.data.DataLoader(traindata, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    \n",
    "    log_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    sampler = SpannerEG(actions=Zs, epsilon=epsilon, tzero=epsilontzero)\n",
    "    opt = torch.optim.Adam(( p for p in model.parameters() if p.requires_grad ), lr=initlr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda = lambda t: sqrt(tzero) / sqrt(tzero + t))\n",
    "    start = time.time()\n",
    "        \n",
    "    print('{:<5s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}'.format(\n",
    "            'n', 'loss', 'since last', 'acc', 'since last', 'reward', 'since last', 'dt (sec)'), \n",
    "          flush=True)\n",
    "    avloss, sincelast, acc, accsincelast, avreward, rewardsincelast = [ EasyAcc() for _ in range(6) ]\n",
    "    \n",
    "    for bno, (Xs, preys) in enumerate(generator):\n",
    "        if bno > 10:\n",
    "            break\n",
    "            \n",
    "        Xs, preys = Xs.to(Zs.device), preys.to(Zs.device)\n",
    "              \n",
    "        with torch.no_grad():\n",
    "            ys = torch.gather(input=preys, dim=1, index=remap.expand(preys.shape[0], -1))        \n",
    "\n",
    "        opt.zero_grad()\n",
    "        logit = model.forward(0.0001 * Xs, Zs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample = sampler.sample(logit, k=k, r=r)\n",
    "            reward = torch.gather(input=ys, dim=1, index=sample).float()\n",
    "            \n",
    "        samplelogit = torch.gather(input=logit, index=sample, dim=1)\n",
    "        loss = log_loss(samplelogit, reward)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.topk(logit, k=k, dim=1)\n",
    "            ypred = torch.gather(input=ys, dim=1, index=pred.indices)\n",
    "            acc += k * torch.mean(ypred).float()\n",
    "            accsincelast += k * torch.mean(ypred).float()\n",
    "            avloss += loss\n",
    "            sincelast += loss\n",
    "            avreward += k * torch.mean(reward)\n",
    "            rewardsincelast += k * torch.mean(reward)\n",
    "\n",
    "        if bno & (bno - 1) == 0:\n",
    "            now = time.time()\n",
    "            print('{:<5d}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}'.format(\n",
    "                    avloss.n, avloss.mean(), sincelast.mean(), acc.mean(), \n",
    "                    accsincelast.mean(), avreward.mean(), rewardsincelast.mean(),\n",
    "                    now - start),\n",
    "                  flush=True)\n",
    "            sincelast, accsincelast, rewardsincelast = [ EasyAcc() for _ in range(3) ]\n",
    "\n",
    "    now = time.time()\n",
    "    print('{:<5d}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}'.format(\n",
    "            avloss.n, avloss.mean(), sincelast.mean(), acc.mean(), \n",
    "            accsincelast.mean(), avreward.mean(), rewardsincelast.mean(),\n",
    "            now - start),\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe35cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = loadMyDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb47b2",
   "metadata": {},
   "source": [
    "Here we use a supervised pre-training step inspired by [Sen et. al.](https://arxiv.org/abs/2102.07800), which allows us to estimate an action embedding using Hellinger PCA.  This is slow-ish (a few minutes) and a memory hog (dozens of gigabytes b/c I'm lazy and didn't implement this out-of-core) so we do it once and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d19f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEmbedding(mydata, rank, seed=2112):\n",
    "    import gzip\n",
    "    \n",
    "    embeds = embed(mydata, batch_size=32, pretrain=50000, rank=rank, seed=seed)\n",
    "    with gzip.open(f'amazon3m.embeds.{rank}.pickle.gz', 'wb') as handle:\n",
    "        import pickle\n",
    "        pickle.dump(embeds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9825c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEmbedding(rank):\n",
    "    import gzip\n",
    "    \n",
    "    with gzip.open(f'amazon3m.embeds.{rank}.pickle.gz', 'rb') as handle:\n",
    "        import pickle\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60de4f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank = 800\n",
      "pretrain\n",
      "n    \tloss    \tsince last\tacc     \tacc since last\tdt (sec)\n",
      "1    \t0.00044781\t0.00044781\t0       \t0       \t6.3293  \n",
      "2    \t0.00045795\t0.0004681\t0.015625\t0.03125 \t7.4911  \n",
      "3    \t0.00045246\t0.00044148\t0.010417\t0       \t8.5895  \n",
      "5    \t0.0004153\t0.00035956\t0.00625 \t0       \t10.838  \n",
      "9    \t0.00040865\t0.00040034\t0.0034722\t0       \t15.13   \n",
      "17   \t0.00043364\t0.00046175\t0.0018382\t0       \t23.812  \n",
      "33   \t0.00044654\t0.00046026\t0.0047348\t0.0078125\t41.039  \n",
      "65   \t0.00044619\t0.00044583\t0.0072115\t0.0097656\t75.519  \n",
      "129  \t0.00044572\t0.00044523\t0.016715\t0.026367\t144.7   \n",
      "257  \t0.00043035\t0.00041486\t0.027602\t0.038574\t282.77  \n",
      "513  \t0.00041687\t0.00040335\t0.045565\t0.063599\t559.83  \n",
      "1025 \t0.00040011\t0.00038331\t0.060793\t0.07605 \t1113.6  \n",
      "1563 \t0.00039106\t0.00037381\t0.069438\t0.085908\t1699.7  \n",
      "train\n",
      "n    \tloss      \tsince last\tacc       \tsince last\treward    \tsince last\tdt (sec)  \n",
      "1    \t0.22785   \t0.22785   \t0.35938   \t0.35938   \t0.34766   \t0.34766   \t6.78566   \n",
      "2    \t0.26241   \t0.29697   \t0.39258   \t0.42578   \t0.38281   \t0.41797   \t19.80504  \n",
      "3    \t0.27194   \t0.29100   \t0.36719   \t0.31641   \t0.36068   \t0.31641   \t26.03117  \n",
      "5    \t0.28476   \t0.30398   \t0.38281   \t0.40625   \t0.37422   \t0.39453   \t38.67078  \n",
      "9    \t0.28185   \t0.27822   \t0.39540   \t0.41113   \t0.38845   \t0.40625   \t63.58444  \n",
      "17   \t0.26340   \t0.24265   \t0.36305   \t0.32666   \t0.35685   \t0.32129   \t114.72449 \n",
      "33   \t0.25942   \t0.25519   \t0.36281   \t0.36255   \t0.35701   \t0.35718   \t215.88565 \n",
      "65   \t0.25807   \t0.25668   \t0.37314   \t0.38379   \t0.36863   \t0.38062   \t412.21248 \n",
      "129  \t0.25833   \t0.25859   \t0.38530   \t0.39764   \t0.38142   \t0.39441   \t813.21524 \n",
      "257  \t0.25528   \t0.25220   \t0.38903   \t0.39279   \t0.38579   \t0.39020   \t1622.92454\n",
      "513  \t0.25240   \t0.24951   \t0.38941   \t0.38979   \t0.38679   \t0.38779   \t3248.79506\n",
      "1025 \t0.25381   \t0.25522   \t0.39915   \t0.40891   \t0.39702   \t0.40727   \t6468.83965\n",
      "2049 \t0.25358   \t0.25335   \t0.40585   \t0.41255   \t0.40404   \t0.41106   \t13042.30136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18ddbde363f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'rank = {rank}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     doit(rank, seed=4545, \n\u001b[0m\u001b[1;32m     18\u001b[0m          \u001b[0minitlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m          \u001b[0mbanditinitlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandittzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-18ddbde363f6>\u001b[0m in \u001b[0;36mdoit\u001b[0;34m(rank, initlr, tzero, banditinitlr, bandittzero, epsilon, epsilontzero, seed, prebs, banditbs)\u001b[0m\n\u001b[1;32m      8\u001b[0m                    batch_size=prebs, pretrain=pretrain, cuda=cuda, seed=seed)\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     train(mydata, k=k, r=r, model=model, actions=embeds, \n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0minitlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbanditinitlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbandittzero\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilontzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilontzero\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0d9c473446a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, k, r, model, actions, initlr, tzero, epsilon, epsilontzero, batch_size, pretrain, cuda, seed)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mavloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msincelast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccsincelast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewardsincelast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mEasyAcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce4c036cc32b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def doit(rank, *, initlr, tzero, banditinitlr, bandittzero, epsilon, epsilontzero, seed, prebs, banditbs):\n",
    "    pretrain, depth, cuda, k, r = 50000, 2, False, 5, 3\n",
    "    \n",
    "    embeds = loadEmbedding(rank=rank)\n",
    "    print('pretrain')\n",
    "    model = presup(mydata, actions=embeds, depth=depth,\n",
    "                   initlr=initlr, tzero=tzero, \n",
    "                   batch_size=prebs, pretrain=pretrain, cuda=cuda, seed=seed)\n",
    "    print('train')\n",
    "    train(mydata, k=k, r=r, model=model, actions=embeds, \n",
    "          initlr=banditinitlr, tzero=bandittzero,\n",
    "          epsilon=epsilon / r, epsilontzero=epsilontzero, \n",
    "          batch_size=banditbs, pretrain=pretrain, cuda=cuda, seed=seed)\n",
    "    \n",
    "for rank in (800,):\n",
    "    print(f'rank = {rank}')\n",
    "    doit(rank, seed=4545, \n",
    "         initlr=1/80, tzero=100, \n",
    "         banditinitlr=1/640, bandittzero=10, \n",
    "         epsilon=(1/10), epsilontzero=10,\n",
    "         prebs=32, banditbs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5814b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank = 800\n",
      "pretrain\n",
      "n    \tloss    \tsince last\tacc     \tacc since last\tdt (sec)\n",
      "1    \t0.00024355\t0.00024355\t0       \t0       \t0.18505 \n",
      "2    \t0.00016816\t9.2777e-05\t0       \t0       \t0.34382 \n",
      "2    \t0.00016816\t0       \t0       \t0       \t0.35121 \n",
      "train\n",
      "n    \tloss      \tsince last\tacc       \tsince last\treward    \tsince last\tdt (sec)  \n",
      "1    \t0.00286   \t0.00286   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t0.26498   \n",
      "2    \t0.00882   \t0.01478   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t0.41026   \n",
      "3    \t0.00854   \t0.00799   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t0.56397   \n",
      "5    \t0.44687   \t1.10436   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t0.85216   \n",
      "9    \t0.25451   \t0.01407   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t1.42909   \n",
      "11   \t0.20864   \t0.00218   \t0.00000   \t0.00000   \t0.00000   \t0.00000   \t1.76446   \n"
     ]
    }
   ],
   "source": [
    "# hack things to get inference times\n",
    "\n",
    "def doit(rank, *, initlr, tzero, banditinitlr, bandittzero, epsilon, epsilontzero, seed, prebs, banditbs):\n",
    "    pretrain, depth, cuda, k, r = 50000, 2, False, 5, 3\n",
    "    \n",
    "    embeds = loadEmbedding(rank=rank)\n",
    "    print('pretrain')\n",
    "    model = presup(mydata, actions=embeds, depth=depth,\n",
    "                   initlr=initlr, tzero=tzero, \n",
    "                   batch_size=prebs, pretrain=pretrain, cuda=cuda, seed=seed)\n",
    "    print('train')\n",
    "    train(mydata, k=k, r=r, model=model, actions=embeds, \n",
    "          initlr=banditinitlr, tzero=bandittzero,\n",
    "          epsilon=epsilon / r, epsilontzero=epsilontzero, \n",
    "          batch_size=banditbs, pretrain=pretrain, cuda=cuda, seed=seed)\n",
    "    \n",
    "for rank in (800,):\n",
    "    print(f'rank = {rank}')\n",
    "    doit(rank, seed=4545, \n",
    "         initlr=1/80, tzero=100, \n",
    "         banditinitlr=1/640, bandittzero=10, \n",
    "         epsilon=(1/10), epsilontzero=10,\n",
    "         prebs=1, banditbs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539fc54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16040545454545455"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.76446 / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d2ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
